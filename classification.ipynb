{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "263351e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Setup\n",
    "# =========================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "# For reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7da84c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Gaussian Noise Layer\n",
    "# =========================\n",
    "\n",
    "class GaussianNoise(nn.Module):\n",
    "    def __init__(self, mean=0.0, std=0.2):\n",
    "        super().__init__()\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            return x + torch.randn_like(x) * self.std + self.mean\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1f96b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, num_features=44, num_classes=6):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_features),\n",
    "            GaussianNoise(0.0, 0.2),\n",
    "            nn.Linear(num_features, 1000),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.Dropout(0.2),\n",
    "            GaussianNoise(0.0, 0.2),\n",
    "            nn.Linear(1000, 200),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.BatchNorm1d(200),\n",
    "            nn.Dropout(0.2),\n",
    "            GaussianNoise(0.0, 0.2),\n",
    "            nn.Linear(200, 200),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.BatchNorm1d(200),\n",
    "            nn.Dropout(0.2),\n",
    "            GaussianNoise(0.0, 0.2),\n",
    "            nn.Linear(200, 200),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.BatchNorm1d(200),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(200, 200),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(200, num_classes)\n",
    "        )\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.model:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5187027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Training & Evaluation\n",
    "# =========================\n",
    "\n",
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            val_loss += criterion(outputs, y).item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            y_true.extend(y.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # For binary classification\n",
    "    if cm.shape == (2, 2):\n",
    "        TN, FP, FN, TP = cm.ravel()\n",
    "        sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    else:\n",
    "        # For multiclass, you might want per-class sensitivity and specificity,\n",
    "        # or macro-averaged values (more complex, depends on your task)\n",
    "        sensitivity, specificity = None, None\n",
    "\n",
    "    return val_loss / len(loader), acc, f1, sensitivity, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3125bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mwr_df_simple = pd.read_csv('mwr_simple.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f387eace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select feature columns (sensor readings)\n",
    "feature_cols = [col for col in mwr_df_simple.columns if col.endswith('int') or col.endswith('sk')]\n",
    "mwr_df_simple['features'] = mwr_df_simple[feature_cols].values.tolist()\n",
    "\n",
    "# Prepare labels and text targets\n",
    "mwr_df_simple['class_label'] = mwr_df_simple['y_binary'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "745c48c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(mwr_df_simple, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0deede1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Dataset and DataLoader\n",
    "# =========================\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.X = torch.tensor(df['features'].tolist(), dtype=torch.float32)\n",
    "        self.y = torch.tensor(df['class_label'].tolist(), dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = TabularDataset(train_df)\n",
    "val_dataset = TabularDataset(val_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "324a23ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 0.6835 | Val Loss: 0.5101 | Acc: 0.7599 | F1: 0.6829 | Sensitivity: 0.9778 | Specificity: 0.0648\n",
      "Epoch 02 | Train Loss: 0.5404 | Val Loss: 0.4987 | Acc: 0.7632 | F1: 0.7390 | Sensitivity: 0.9103 | Specificity: 0.2939\n",
      "Epoch 03 | Train Loss: 0.5180 | Val Loss: 0.4976 | Acc: 0.7572 | F1: 0.7441 | Sensitivity: 0.8805 | Specificity: 0.3639\n",
      "Epoch 04 | Train Loss: 0.5141 | Val Loss: 0.4893 | Acc: 0.7721 | F1: 0.7489 | Sensitivity: 0.9160 | Specificity: 0.3129\n",
      "Epoch 05 | Train Loss: 0.4994 | Val Loss: 0.4777 | Acc: 0.7719 | F1: 0.7618 | Sensitivity: 0.8840 | Specificity: 0.4140\n",
      "Epoch 06 | Train Loss: 0.4954 | Val Loss: 0.4879 | Acc: 0.7568 | F1: 0.7519 | Sensitivity: 0.8572 | Specificity: 0.4365\n",
      "Epoch 07 | Train Loss: 0.4900 | Val Loss: 0.4807 | Acc: 0.7642 | F1: 0.7589 | Sensitivity: 0.8640 | Specificity: 0.4460\n",
      "Epoch 08 | Train Loss: 0.4877 | Val Loss: 0.4769 | Acc: 0.7628 | F1: 0.7580 | Sensitivity: 0.8610 | Specificity: 0.4494\n",
      "Epoch 09 | Train Loss: 0.4773 | Val Loss: 0.4827 | Acc: 0.7550 | F1: 0.7587 | Sensitivity: 0.8242 | Specificity: 0.5341\n",
      "Epoch 10 | Train Loss: 0.4791 | Val Loss: 0.4734 | Acc: 0.7634 | F1: 0.7647 | Sensitivity: 0.8393 | Specificity: 0.5212\n",
      "Epoch 11 | Train Loss: 0.4741 | Val Loss: 0.4773 | Acc: 0.7560 | F1: 0.7588 | Sensitivity: 0.8285 | Specificity: 0.5246\n",
      "Epoch 12 | Train Loss: 0.4715 | Val Loss: 0.4630 | Acc: 0.7702 | F1: 0.7668 | Sensitivity: 0.8618 | Specificity: 0.4780\n",
      "Epoch 13 | Train Loss: 0.4712 | Val Loss: 0.4800 | Acc: 0.7562 | F1: 0.7625 | Sensitivity: 0.8128 | Specificity: 0.5756\n",
      "Epoch 14 | Train Loss: 0.4687 | Val Loss: 0.4684 | Acc: 0.7646 | F1: 0.7678 | Sensitivity: 0.8326 | Specificity: 0.5480\n",
      "Epoch 15 | Train Loss: 0.4658 | Val Loss: 0.4662 | Acc: 0.7646 | F1: 0.7662 | Sensitivity: 0.8393 | Specificity: 0.5264\n",
      "Epoch 16 | Train Loss: 0.4639 | Val Loss: 0.4740 | Acc: 0.7599 | F1: 0.7653 | Sensitivity: 0.8193 | Specificity: 0.5704\n",
      "Epoch 17 | Train Loss: 0.4646 | Val Loss: 0.4638 | Acc: 0.7640 | F1: 0.7670 | Sensitivity: 0.8326 | Specificity: 0.5454\n",
      "Epoch 18 | Train Loss: 0.4584 | Val Loss: 0.4723 | Acc: 0.7554 | F1: 0.7633 | Sensitivity: 0.8041 | Specificity: 0.5998\n",
      "Epoch 19 | Train Loss: 0.4554 | Val Loss: 0.4728 | Acc: 0.7595 | F1: 0.7658 | Sensitivity: 0.8147 | Specificity: 0.5834\n",
      "Epoch 20 | Train Loss: 0.4567 | Val Loss: 0.4690 | Acc: 0.7665 | F1: 0.7723 | Sensitivity: 0.8206 | Specificity: 0.5938\n",
      "Epoch 21 | Train Loss: 0.4545 | Val Loss: 0.4633 | Acc: 0.7671 | F1: 0.7689 | Sensitivity: 0.8396 | Specificity: 0.5359\n",
      "Epoch 22 | Train Loss: 0.4500 | Val Loss: 0.4680 | Acc: 0.7585 | F1: 0.7660 | Sensitivity: 0.8076 | Specificity: 0.6016\n",
      "Epoch 23 | Train Loss: 0.4527 | Val Loss: 0.4715 | Acc: 0.7589 | F1: 0.7661 | Sensitivity: 0.8095 | Specificity: 0.5972\n",
      "Epoch 24 | Train Loss: 0.4504 | Val Loss: 0.4553 | Acc: 0.7698 | F1: 0.7707 | Sensitivity: 0.8453 | Specificity: 0.5290\n",
      "Epoch 25 | Train Loss: 0.4508 | Val Loss: 0.4550 | Acc: 0.7758 | F1: 0.7751 | Sensitivity: 0.8556 | Specificity: 0.5212\n",
      "Epoch 26 | Train Loss: 0.4492 | Val Loss: 0.4572 | Acc: 0.7729 | F1: 0.7775 | Sensitivity: 0.8301 | Specificity: 0.5903\n",
      "Epoch 27 | Train Loss: 0.4442 | Val Loss: 0.4533 | Acc: 0.7719 | F1: 0.7748 | Sensitivity: 0.8374 | Specificity: 0.5627\n",
      "Epoch 28 | Train Loss: 0.4459 | Val Loss: 0.4564 | Acc: 0.7797 | F1: 0.7805 | Sensitivity: 0.8518 | Specificity: 0.5497\n",
      "Epoch 29 | Train Loss: 0.4396 | Val Loss: 0.4537 | Acc: 0.7679 | F1: 0.7731 | Sensitivity: 0.8247 | Specificity: 0.5869\n",
      "Epoch 30 | Train Loss: 0.4425 | Val Loss: 0.4531 | Acc: 0.7807 | F1: 0.7809 | Sensitivity: 0.8553 | Specificity: 0.5428\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Run Training Loop\n",
    "# =========================\n",
    "\n",
    "model = ClassificationModel(num_features=44, num_classes=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 30\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss, acc, f1, sensitivity, specificity = evaluate(model, val_loader, criterion)\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
    "        f\"Acc: {acc:.4f} | F1: {f1:.4f} | Sensitivity: {sensitivity:.4f} | Specificity: {specificity:.4f}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
