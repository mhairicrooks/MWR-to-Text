{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75370a82",
   "metadata": {},
   "source": [
    "### Initial Multitask Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba88fbfa",
   "metadata": {},
   "source": [
    "#### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "417184d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn # neural network layers and modules\n",
    "import torch.optim as optim # optimisers\n",
    "from torch.utils.data import DataLoader, Dataset # data batching tools\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration # huggingface T5 model + tokenizer\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix # sklearn metrics for evaluation\n",
    "import torchmetrics # extra metrics\n",
    "from model import MultitaskModel, train, evaluate\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ceb216",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23831d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "mwr_df_simple = pd.read_csv('mwr_simple.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ceb880",
   "metadata": {},
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff2bfc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Examination ID', 'Conclusion', 'r:Th', 'Weight', 'Height',\n",
      "       'Ambient temperature', 'r:AgeInYears', 'Mammary diameter', 'Cycle',\n",
      "       'Day from the first day', 'Hormonal medications',\n",
      "       'Cancer family history', 'Breast operations', 'Num of pregnancies',\n",
      "       'R1 int', 'L1 int', 'R2 int', 'L2 int', 'R3 int', 'L3 int', 'R4 int',\n",
      "       'L4 int', 'R5 int', 'L5 int', 'R6 int', 'L6 int', 'R7 int', 'L7 int',\n",
      "       'R8 int', 'L8 int', 'R9 int', 'L9 int', 'T1 int', 'T2 int', 'R0 int',\n",
      "       'L0 int', 'R1 sk', 'L1 sk', 'R2 sk', 'L2 sk', 'R3 sk', 'L3 sk', 'R4 sk',\n",
      "       'L4 sk', 'R5 sk', 'L5 sk', 'R6 sk', 'L6 sk', 'R7 sk', 'L7 sk', 'R8 sk',\n",
      "       'L8 sk', 'R9 sk', 'L9 sk', 'T1 sk', 'T2 sk', 'R0 sk', 'L0 sk',\n",
      "       'Conclusion (Tr)', 'Synthetic_Conclusion'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(mwr_df_simple.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c76ee541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select feature columns (sensor readings)\n",
    "feature_cols = [col for col in mwr_df_simple.columns if col.endswith('int') or col.endswith('sk')]\n",
    "mwr_df_simple['features'] = mwr_df_simple[feature_cols].values.tolist()\n",
    "\n",
    "# Prepare labels and text targets\n",
    "mwr_df_simple['class_label'] = mwr_df_simple['r:Th'].astype(int)\n",
    "mwr_df_simple['synthetic_description'] = mwr_df_simple['Synthetic_Conclusion']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f307bd0c",
   "metadata": {},
   "source": [
    "### Split Data into Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "744c2588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a small sample for CPU testing\n",
    "mwr_df_simple = mwr_df_simple.sample(n=200, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc879070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% training, 15% validation, 15% testing\n",
    "train_simple_df, temp_simple_df = train_test_split(mwr_df_simple, test_size=0.3, random_state=42)\n",
    "val_simple_df, test_simple_df = train_test_split(temp_simple_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35303487",
   "metadata": {},
   "source": [
    "### Model Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "072fdbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "# Define Dataset class (same as before)\n",
    "class MultitaskDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=64):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        features = torch.tensor(row['features'], dtype=torch.float)\n",
    "        label = torch.tensor(row['class_label'], dtype=torch.long)\n",
    "        text = row['synthetic_description']\n",
    "\n",
    "        tokenized = self.tokenizer(text, padding='max_length', truncation=True, max_length=self.max_length, return_tensors='pt')\n",
    "        input_ids = tokenized['input_ids'].squeeze(0)\n",
    "        attention_mask = tokenized['attention_mask'].squeeze(0)\n",
    "\n",
    "        return features, label, input_ids, attention_mask, tokenized['input_ids'].squeeze(0)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = MultitaskDataset(train_simple_df, tokenizer)\n",
    "val_dataset = MultitaskDataset(val_simple_df, tokenizer)\n",
    "test_dataset = MultitaskDataset(test_simple_df, tokenizer)\n",
    "\n",
    "# Create dataloaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = MultitaskModel(num_classes=6).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae16da0",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66c63a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 13.6455\n",
      "Validation loss: 10.5899\n",
      "Validation metrics: {'accuracy': 0.0, 'f1_score': 0.0}\n",
      "\n",
      "Epoch 2/10\n",
      "Training loss: 11.1451\n",
      "Validation loss: 7.1417\n",
      "Validation metrics: {'accuracy': 0.03333333333333333, 'f1_score': 0.002898550724637681}\n",
      "\n",
      "Epoch 3/10\n",
      "Training loss: 8.1552\n",
      "Validation loss: 4.2677\n",
      "Validation metrics: {'accuracy': 0.06666666666666667, 'f1_score': 0.06666666666666667}\n",
      "\n",
      "Epoch 4/10\n",
      "Training loss: 6.6522\n",
      "Validation loss: 2.6388\n",
      "Validation metrics: {'accuracy': 0.2, 'f1_score': 0.16982456140350877}\n",
      "\n",
      "Epoch 5/10\n",
      "Training loss: 4.6689\n",
      "Validation loss: 2.0644\n",
      "Validation metrics: {'accuracy': 0.23333333333333334, 'f1_score': 0.22872566030460767}\n",
      "\n",
      "Epoch 6/10\n",
      "Training loss: 3.8420\n",
      "Validation loss: 2.0074\n",
      "Validation metrics: {'accuracy': 0.26666666666666666, 'f1_score': 0.20701754385964913}\n",
      "\n",
      "Epoch 7/10\n",
      "Training loss: 3.5386\n",
      "Validation loss: 2.0024\n",
      "Validation metrics: {'accuracy': 0.3, 'f1_score': 0.21375661375661373}\n",
      "\n",
      "Epoch 8/10\n",
      "Training loss: 3.1408\n",
      "Validation loss: 2.0143\n",
      "Validation metrics: {'accuracy': 0.26666666666666666, 'f1_score': 0.20168067226890757}\n",
      "\n",
      "Epoch 9/10\n",
      "Training loss: 2.9358\n",
      "Validation loss: 2.0231\n",
      "Validation metrics: {'accuracy': 0.26666666666666666, 'f1_score': 0.1947089947089947}\n",
      "\n",
      "Epoch 10/10\n",
      "Training loss: 2.7506\n",
      "Validation loss: 2.0229\n",
      "Validation metrics: {'accuracy': 0.3333333333333333, 'f1_score': 0.2613756613756613}\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10  # or whatever you choose\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train(model, train_loader, optimizer, device)\n",
    "    print(f\"Training loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_metrics = evaluate(model, val_loader, device)\n",
    "    print(f\"Validation loss: {val_loss:.4f}\")\n",
    "    print(f\"Validation metrics: {val_metrics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c73b2fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.9588\n",
      "Test metrics: {'accuracy': 0.4666666666666667, 'f1_score': 0.4273342670401494}\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on test set\n",
    "test_loss, test_metrics = evaluate(model, test_loader, device)\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "print(f\"Test metrics: {test_metrics}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
