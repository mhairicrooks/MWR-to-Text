{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75370a82",
   "metadata": {},
   "source": [
    "### Initial Multitask Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba88fbfa",
   "metadata": {},
   "source": [
    "#### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "417184d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn # neural network layers and modules\n",
    "import torch.optim as optim # optimisers\n",
    "from torch.utils.data import DataLoader, Dataset # data batching tools\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration # huggingface T5 model + tokenizer\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix # sklearn metrics for evaluation\n",
    "import torchmetrics # extra metrics\n",
    "from model import MultitaskModel, MultitaskDataset, train, evaluate\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ceb216",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23831d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "mwr_df_simple = pd.read_csv('mwr_simple.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ceb880",
   "metadata": {},
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff2bfc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Examination ID', 'Conclusion', 'r:Th', 'Weight', 'Height',\n",
      "       'Ambient temperature', 'r:AgeInYears', 'Mammary diameter', 'Cycle',\n",
      "       'Day from the first day', 'Hormonal medications',\n",
      "       'Cancer family history', 'Breast operations', 'Num of pregnancies',\n",
      "       'R1 int', 'L1 int', 'R2 int', 'L2 int', 'R3 int', 'L3 int', 'R4 int',\n",
      "       'L4 int', 'R5 int', 'L5 int', 'R6 int', 'L6 int', 'R7 int', 'L7 int',\n",
      "       'R8 int', 'L8 int', 'R9 int', 'L9 int', 'T1 int', 'T2 int', 'R0 int',\n",
      "       'L0 int', 'R1 sk', 'L1 sk', 'R2 sk', 'L2 sk', 'R3 sk', 'L3 sk', 'R4 sk',\n",
      "       'L4 sk', 'R5 sk', 'L5 sk', 'R6 sk', 'L6 sk', 'R7 sk', 'L7 sk', 'R8 sk',\n",
      "       'L8 sk', 'R9 sk', 'L9 sk', 'T1 sk', 'T2 sk', 'R0 sk', 'L0 sk',\n",
      "       'Conclusion (Tr)', 'Synthetic_Conclusion'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(mwr_df_simple.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c76ee541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select feature columns (sensor readings)\n",
    "feature_cols = [col for col in mwr_df_simple.columns if col.endswith('int') or col.endswith('sk')]\n",
    "mwr_df_simple['features'] = mwr_df_simple[feature_cols].values.tolist()\n",
    "\n",
    "# Prepare labels and text targets\n",
    "mwr_df_simple['class_label'] = mwr_df_simple['r:Th'].astype(int)\n",
    "mwr_df_simple['synthetic_description'] = mwr_df_simple['Synthetic_Conclusion']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f307bd0c",
   "metadata": {},
   "source": [
    "### Split Data into Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "744c2588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a small sample for CPU testing\n",
    "mwr_df_simple = mwr_df_simple.sample(n=200, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc879070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% training, 15% validation, 15% testing\n",
    "train_simple_df, temp_simple_df = train_test_split(mwr_df_simple, test_size=0.3, random_state=42)\n",
    "val_simple_df, test_simple_df = train_test_split(temp_simple_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35303487",
   "metadata": {},
   "source": [
    "### Model Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072fdbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = MultitaskDataset(train_simple_df, tokenizer)\n",
    "val_dataset = MultitaskDataset(val_simple_df, tokenizer)\n",
    "test_dataset = MultitaskDataset(test_simple_df, tokenizer)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = MultitaskModel(num_classes=6).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae16da0",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66c63a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 13.8391\n",
      "Validation loss: 10.2960\n",
      "Validation metrics: {'accuracy': 0.1, 'f1_score': 0.019354838709677417}\n",
      "\n",
      "Epoch 2/10\n",
      "Training loss: 10.8135\n",
      "Validation loss: 7.0710\n",
      "Validation metrics: {'accuracy': 0.1, 'f1_score': 0.01818181818181818}\n",
      "\n",
      "Epoch 3/10\n",
      "Training loss: 8.7286\n",
      "Validation loss: 4.2547\n",
      "Validation metrics: {'accuracy': 0.1, 'f1_score': 0.01875}\n",
      "\n",
      "Epoch 4/10\n",
      "Training loss: 6.3370\n",
      "Validation loss: 2.6854\n",
      "Validation metrics: {'accuracy': 0.13333333333333333, 'f1_score': 0.07268817204301076}\n",
      "\n",
      "Epoch 5/10\n",
      "Training loss: 4.7653\n",
      "Validation loss: 2.0857\n",
      "Validation metrics: {'accuracy': 0.06666666666666667, 'f1_score': 0.014285714285714285}\n",
      "\n",
      "Epoch 6/10\n",
      "Training loss: 3.7458\n",
      "Validation loss: 2.0155\n",
      "Validation metrics: {'accuracy': 0.13333333333333333, 'f1_score': 0.0707070707070707}\n",
      "\n",
      "Epoch 7/10\n",
      "Training loss: 3.4318\n",
      "Validation loss: 2.0085\n",
      "Validation metrics: {'accuracy': 0.06666666666666667, 'f1_score': 0.016}\n",
      "\n",
      "Epoch 8/10\n",
      "Training loss: 3.0601\n",
      "Validation loss: 2.0152\n",
      "Validation metrics: {'accuracy': 0.13333333333333333, 'f1_score': 0.10147008547008546}\n",
      "\n",
      "Epoch 9/10\n",
      "Training loss: 3.0558\n",
      "Validation loss: 2.0227\n",
      "Validation metrics: {'accuracy': 0.1, 'f1_score': 0.05548654244306418}\n",
      "\n",
      "Epoch 10/10\n",
      "Training loss: 3.0116\n",
      "Validation loss: 2.0293\n",
      "Validation metrics: {'accuracy': 0.1, 'f1_score': 0.057025641025641026}\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10  # or whatever you choose\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train(model, train_loader, optimizer, device)\n",
    "    print(f\"Training loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_metrics = evaluate(model, val_loader, device)\n",
    "    print(f\"Validation loss: {val_loss:.4f}\")\n",
    "    print(f\"Validation metrics: {val_metrics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c73b2fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.0423\n",
      "Test metrics: {'accuracy': 0.06666666666666667, 'f1_score': 0.10959595959595961}\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on test set\n",
    "test_loss, test_metrics = evaluate(model, test_loader, device)\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "print(f\"Test metrics: {test_metrics}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
